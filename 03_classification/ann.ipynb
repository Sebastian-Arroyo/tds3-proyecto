{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8131869c-97c0-40c0-8f61-fe9ad1101ce9",
   "metadata": {},
   "source": [
    "# Miniproyecto #3: Redes neuronales artificiales (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8702e2-150b-4879-a915-68ac7fc21142",
   "metadata": {},
   "source": [
    "\n",
    "**Autores:**\n",
    "*   Jorge Sebastián Arroyo Estrada CC. 1193482707\n",
    "*   César Augusto Montoya Ocampo CC. 1036681523\n",
    "\n",
    "**Tratamiento de Señales III**\n",
    "\n",
    "**Facultad de Ingeniería**\n",
    "\n",
    "**Universidad de Antioquia**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085328da-239d-490a-9964-064edf54af46",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbdc4c-44a2-448f-bb3a-2e72df5e9a75",
   "metadata": {},
   "source": [
    "Importa diversas bibliotecas para el análisis y procesamiento de datos, así como para la implementación y evaluación de modelos de aprendizaje automático y redes neuronales. Se utilizan bibliotecas estándar como `json`, `os`, `pickle` y `datetime` para manejo de archivos y tiempos, además de `itertools` para generar combinaciones de parámetros. `matplotlib`, `numpy` y `pandas` se emplean para visualización y manipulación de datos. Las métricas y herramientas de `sklearn`, como `accuracy_score`, `f1_score`, y `confusion_matrix`, se usan para evaluar el rendimiento de modelos, mientras que `GridSearchCV` y `train_test_split` facilitan la optimización y la partición de los datos. Además, se importan componentes de `keras` como `Sequential`, `Input`, y `Dense` para construir redes neuronales, así como el envoltorio `KerasClassifier` para integrar modelos de `Keras` con `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e37ae52-54a5-49ea-a87c-b16a28572b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from classification import main_pipeline, plot_grouped_metrics\n",
    "from keras import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1e08f-b485-4172-9862-2a5fb8941b1a",
   "metadata": {},
   "source": [
    "## Globales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3562582-093c-41d9-897d-d3f29aa50ec9",
   "metadata": {},
   "source": [
    "Definir rutas para archivos de bases de datos, configurando parámetros globales para un modelo de ML. Establece la ruta base de las características (`DB_BASE_PATH`) y genera listas de nombres y rutas de archivos para cuatro bases de datos con resoluciones de 64x64 y 128x128, diferenciando entre características y PCA. También define la ruta para un archivo de etiquetas (`LABELS_PATH`) y crea un directorio para almacenar los resultados del modelo (`RESULTS_FOLDER`). Se configuran parámetros globales como el estado aleatorio (`RANDOM_STATE`), la validación cruzada (`K`), el estimador con el parámetro de búsqueda de la cuadrícula (`PARAM_GRID`), y las métricas de evaluación como `precision`, `accuracy`, `recall` y `f1_score`. La métrica principal para la optimización del modelo es la puntuación F1 ponderada (`f1_weighted`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dc6652-72d0-4e54-b6d8-65d96eeda324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database files paths\n",
    "DB_BASE_PATH = Path(\"../02_features/\")\n",
    "RESOLUTIONS = 2 * [64, 128]\n",
    "DB_NAMES = [\n",
    "    f\"DB {RESOLUTIONS[i]}×{RESOLUTIONS[i]}{' PCA' if i >= 2 else ''}\" for i in range(4)\n",
    "]\n",
    "DB_PATHS = [\n",
    "    DB_BASE_PATH / f\"{'features' if i < 2 else 'pca'}_{RESOLUTIONS[i]}.csv\"\n",
    "    for i in range(4)\n",
    "]\n",
    "DB_DICT = {name: path for name, path in zip(DB_NAMES, DB_PATHS)}\n",
    "\n",
    "# Classes to labels mapping file path\n",
    "LABELS_PATH = DB_BASE_PATH / \"labels.csv\"\n",
    "\n",
    "# Results folder\n",
    "RESULTS_FOLDER = Path(\"./ann_results/\")\n",
    "RESULTS_FOLDER.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3ed5-f4dc-4f88-93ee-03a0c0224af8",
   "metadata": {},
   "source": [
    "Define parámetros globales y configura un entorno para crear y evaluar modelos de redes neuronales utilizando `keras` y `scikit-learn`. `RANDOM_STATE` asegura reproducibilidad, mientras que `K` define el número de particiones en validaciones cruzadas. La función `create_model` genera dinámicamente un modelo `Sequential` de `keras`, permitiendo personalizar capas ocultas, funciones de activación, optimizador y métricas. Este modelo se envuelve con `KerasClassifier` para integrarlo con `scikit-learn`.\n",
    "\n",
    "Se establecen `NEURONS` como una lista de potencias de 2 para definir el número de neuronas, mientras que `ACTIVATIONS` genera combinaciones de funciones de activación (`relu`, `leaky_relu`, `tanh`). `PARAM_GRID` configura un espacio de hiperparámetros para `GridSearchCV`, incluyendo configuraciones dinámicas como dimensiones de entrada y salida del modelo (`input_dim` y `output_dim`).  \n",
    "\n",
    "Finalmente, se definen métricas de evaluación en `SCORE_METRICS`, incluyendo `accuracy`, `precision`, `recall` y `f1`, ponderadas por clases y con manejo de divisiones por cero. La métrica principal se establece como la última de esta lista (`f1_weighted`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4feb65f-ea1f-44f0-8762-236c0dd6f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "RANDOM_STATE = 3\n",
    "K = 5\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(\n",
    "    neurons,\n",
    "    activations,\n",
    "    input_dim,\n",
    "    output_dim,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Dynamically creates a Keras Sequential model.\n",
    "\n",
    "    Parameters:\n",
    "        hidden_layers (int): Number of hidden layers.\n",
    "        neurons (int): Number of neurons in each hidden layer.\n",
    "        activation (str): Activation function for the layers.\n",
    "        optimizer (str): Optimizer for compiling the model.\n",
    "\n",
    "    Returns:\n",
    "        model: A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "    # Hidden layers\n",
    "    for i, activation in enumerate(activations):\n",
    "        model.add(Dense(neurons // (2**i), activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=output_dim, activation=\"softmax\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "ESTIMATOR = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "NEURONS = [2**i for i in range(4, 9)]\n",
    "ACTIVATION_FNS = [\"relu\", \"leaky_relu\", \"tanh\"]\n",
    "ACTIVATIONS = [\n",
    "    list(combo) for n in range(1, 4) for combo in product(ACTIVATION_FNS, repeat=n)\n",
    "]\n",
    "\n",
    "PARAM_GRID = {\n",
    "    \"model__neurons\": NEURONS,\n",
    "    \"model__activations\": ACTIVATIONS,\n",
    "    \"model__input_dim\": None,\n",
    "    \"model__output_dim\": None,\n",
    "    \"model__optimizer\": [\"adam\"],\n",
    "    \"model__loss\": [\"sparse_categorical_crossentropy\"],\n",
    "}\n",
    "\n",
    "SCORE_METRICS = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision_weighted\": make_scorer(\n",
    "        precision_score, average=\"weighted\", zero_division=np.nan\n",
    "    ),\n",
    "    \"recall_weighted\": make_scorer(\n",
    "        recall_score, average=\"weighted\", zero_division=np.nan\n",
    "    ),\n",
    "    \"f1_weighted\": make_scorer(f1_score, average=\"weighted\", zero_division=np.nan),\n",
    "}\n",
    "MAIN_SCORE_METRIC = list(SCORE_METRICS.keys())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f445d-904b-4812-9a8e-277e9461fda3",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5baf1e-5023-4ab5-8788-e457c4481692",
   "metadata": {},
   "source": [
    "Este código define varias funciones para manejar el procesamiento de datos, entrenamiento de modelos y almacenamiento de resultados:\n",
    "\n",
    "- `load_and_preprocess_data`: Carga un archivo CSV, separa las características y las etiquetas, y normaliza las características utilizando `StandardScaler`.\n",
    "- `load_label_mapping`: Carga un archivo CSV con etiquetas de clases y devuelve un diccionario que mapea los números de clase a nombres legibles.\n",
    "- `load_results`: Carga los resultados previamente guardados de un experimento, incluyendo el mejor modelo entrenado, métricas de entrenamiento, validación y prueba, y el tiempo de inferencia. Retorna `None` si no se encuentran los archivos o si ocurre un error.\n",
    "- `save_results`: Guarda los resultados de un experimento en disco, incluyendo las métricas de evaluación, el tiempo de inferencia y el mejor modelo entrenado en formatos JSON y pickle.\n",
    "- `grid_search_cv`: Realiza una búsqueda en cuadrícula para optimizar los hiperparámetros de un modelo de aprendizaje automático, utilizando validación cruzada y varias métricas de evaluación. Retorna el mejor modelo, las métricas de entrenamiento y validación promedio, y el tiempo de inferencia.\n",
    "- `evaluate_model`: Evalúa el rendimiento de un modelo calculando métricas como precisión, recall, F1 y exactitud sobre las etiquetas verdaderas y predichas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109fe6b-c4be-4f2b-9dfb-e90a586d14b3",
   "metadata": {},
   "source": [
    "Funciones misceláneas para mostrar los resultados en pantalla de manera ordenada:\n",
    "- `print_results`: Muestra de forma estructurada las métricas de evaluación del modelo para los conjuntos de entrenamiento, validación y prueba, formateándolas como porcentajes. También imprime el tiempo total de inferencia.\n",
    "- `plot_metrics`: Genera un gráfico de barras que representa las métricas de evaluación del modelo en porcentajes, con el objetivo de visualizar el desempeño de manera clara y comprensible.\n",
    "- `plot_confusion_matrix`: Crea y visualiza una matriz de confusión basada en las etiquetas reales y predichas, permitiendo identificar patrones de errores en las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b467c50-3ed9-47c8-95b3-09b98d05841c",
   "metadata": {},
   "source": [
    "El código principal que carga y preprocesa los datos desde un archivo CSV, estandariza las características y obtiene un mapeo de etiquetas (1). Luego divide los datos en conjuntos de entrenamiento y prueba, reservando un 20% para este último (2). Intenta cargar resultados previos para evitar cálculos redundantes (3). Si no existen, realiza una búsqueda de hiperparámetros mediante validación cruzada para encontrar el mejor modelo (4). Posteriormente, evalúa el modelo en el conjunto de prueba, calcula métricas clave, imprime los resultados e informa sobre el tiempo de inferencia (5). Si los resultados son nuevos, los guarda y genera visualizaciones como gráficos de métricas y matrices de confusión (6). Finalmente, retorna las métricas calculadas para entrenamiento, validación y prueba (7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d26c7-b872-42e2-a241-c18b38568120",
   "metadata": {},
   "source": [
    "## Aplicar ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c819e24-2342-41a2-ad63-2707082ffe1a",
   "metadata": {},
   "source": [
    "Ejecución de todo el código para cada una de las bases de datos disponibles, para ambas resoluciones y cuando se empleó PCA o no para la reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503498c3-2a92-4cf2-974a-b09766435525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_scores = {}\n",
    "for name, path in DB_DICT.items():\n",
    "    _, _, test_score = main_pipeline(\n",
    "        name,\n",
    "        path,\n",
    "        LABELS_PATH,\n",
    "        RESULTS_FOLDER,\n",
    "        RANDOM_STATE,\n",
    "        ESTIMATOR,\n",
    "        PARAM_GRID,\n",
    "        K,\n",
    "        SCORE_METRICS,\n",
    "        MAIN_SCORE_METRIC,\n",
    "    )\n",
    "    test_scores[name] = test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c41c8-e8d7-4330-90db-d890954fd31c",
   "metadata": {},
   "source": [
    "Graficar todas las métricas de prueba para cada una de las bases de datos, para así poder ver gráficamente cuál de las bases de datos nos entregó un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494323eb-8b7f-4d0f-8303-686a01b1c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_metrics(test_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
